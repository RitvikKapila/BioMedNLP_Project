{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vLLM trial --FAILED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tokenizer class LlamaTokenizer does not exist or is not currently imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17660\\2235238311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"amazon/MistralLite\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8\u001b[0m model = AutoModelForCausalLM.from_pretrained(model_id,\n",
      "\u001b[0;32m      9\u001b[0m                                              \u001b[0mtorch_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Anaconda\\anaconda3\\envs\\ml_env_py37\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtokenizer_class\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    525\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m--> 526\u001b[1;33m                     \u001b[1;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    527\u001b[0m                 )\n",
      "\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Tokenizer class LlamaTokenizer does not exist or is not currently imported."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"amazon/MistralLite\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             use_flash_attention_2=True,\n",
    "                                             device_map=\"auto\",)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "prompt = \"<|prompter|>What are the main challenges to support a long context for LLM?</s><|assistant|>\"\n",
    "\n",
    "sequences = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=False,\n",
    "    return_full_text=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3.5 16k trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = '<insert API key here>' )        # key removed for privacy, use appropriate key here\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = 'Patients_Datewise_Texts_With_First_Occurance'\n",
    "\n",
    "csv_files = glob.glob(os.path.join(directory_path, '*.csv'))\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FIRST_OCCURANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2123-08-23</td>\n",
       "      <td>[**2123-8-23**] 12:30 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2123-08-24</td>\n",
       "      <td>Smicu nsg admission note\\n65 women recently dx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2123-08-25</td>\n",
       "      <td>[**2123-8-25**] 9:02 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2123-08-26</td>\n",
       "      <td>[**2123-8-26**] 2:17 PM\\n MR HEAD W &amp; W/O CONT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CHARTDATE                                               TEXT  \\\n",
       "0  2123-08-23  [**2123-8-23**] 12:30 PM\\n CHEST (PORTABLE AP)...   \n",
       "1  2123-08-24  Smicu nsg admission note\\n65 women recently dx...   \n",
       "2  2123-08-25  [**2123-8-25**] 9:02 PM\\n CHEST (PORTABLE AP) ...   \n",
       "3  2123-08-26  [**2123-8-26**] 2:17 PM\\n MR HEAD W & W/O CONT...   \n",
       "\n",
       "   FIRST_OCCURANCE  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FIRST_OCCURANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2123-08-23</td>\n",
       "      <td>[**2123-8-23**] 12:30 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2123-08-24</td>\n",
       "      <td>Smicu nsg admission note\\n65 women recently dx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2123-08-25</td>\n",
       "      <td>[**2123-8-25**] 9:02 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2123-08-26</td>\n",
       "      <td>[**2123-8-26**] 2:17 PM\\n MR HEAD W &amp; W/O CONT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2123-08-27</td>\n",
       "      <td>[**2123-8-27**] 12:51 AM\\n CHEST (PORTABLE AP)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2123-08-29</td>\n",
       "      <td>[**2123-8-29**] 2:32 PM\\n CHEST (PA &amp; LAT); CH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2123-08-30</td>\n",
       "      <td>[**2123-8-30**] 6:18 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2123-08-31</td>\n",
       "      <td>[**2123-8-31**] 10:57 AM\\n CHEST (PORTABLE AP)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2123-09-01</td>\n",
       "      <td>[**2123-9-1**] 7:09 AM\\n CHEST (PORTABLE AP)  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2123-09-02</td>\n",
       "      <td>[**2123-9-2**] 8:33 AM\\n CHEST (PORTABLE AP)  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2123-09-06</td>\n",
       "      <td>[**2123-9-6**] 10:11 AM\\n CHEST (PA &amp; LAT)    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2123-09-17</td>\n",
       "      <td>Admission Date:  [**2123-8-23**]              ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHARTDATE                                               TEXT  \\\n",
       "0   2123-08-23  [**2123-8-23**] 12:30 PM\\n CHEST (PORTABLE AP)...   \n",
       "1   2123-08-24  Smicu nsg admission note\\n65 women recently dx...   \n",
       "2   2123-08-25  [**2123-8-25**] 9:02 PM\\n CHEST (PORTABLE AP) ...   \n",
       "3   2123-08-26  [**2123-8-26**] 2:17 PM\\n MR HEAD W & W/O CONT...   \n",
       "4   2123-08-27  [**2123-8-27**] 12:51 AM\\n CHEST (PORTABLE AP)...   \n",
       "5   2123-08-29  [**2123-8-29**] 2:32 PM\\n CHEST (PA & LAT); CH...   \n",
       "6   2123-08-30  [**2123-8-30**] 6:18 PM\\n CHEST (PORTABLE AP) ...   \n",
       "7   2123-08-31  [**2123-8-31**] 10:57 AM\\n CHEST (PORTABLE AP)...   \n",
       "8   2123-09-01  [**2123-9-1**] 7:09 AM\\n CHEST (PORTABLE AP)  ...   \n",
       "9   2123-09-02  [**2123-9-2**] 8:33 AM\\n CHEST (PORTABLE AP)  ...   \n",
       "10  2123-09-06  [**2123-9-6**] 10:11 AM\\n CHEST (PA & LAT)    ...   \n",
       "11  2123-09-17  Admission Date:  [**2123-8-23**]              ...   \n",
       "\n",
       "    FIRST_OCCURANCE  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  \n",
       "10                1  \n",
       "11                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'Patients_Datewise_Texts_With_First_Occurance'\n",
    "\n",
    "csv_files = glob.glob(os.path.join(directory_path, '*.csv'))\n",
    "dfs = []\n",
    "\n",
    "already_saved = glob.glob(os.path.join('patients_datewise_gpt35', '*.csv'))\n",
    "\n",
    "for csv_file in tqdm(csv_files):\n",
    "    out_filename = 'gpt35_16k_' + csv_file.split('\\\\')[-1]\n",
    "    if os.path.join('patients_datewise_gpt35', out_filename) in already_saved:\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    res, summaries, answers = [], [], []\n",
    "    summary = ''\n",
    "    token_len_exceeded_error = False\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            text = 'Prior patient reports summary: ' + summary + '\\nCurrent report:\\n' + row['TEXT']\n",
    "            start = time.time()\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an assistant for a medical practitioner, skilled in analyzing and summarizing medical notes and reports.\"},\n",
    "                    {\"role\": \"user\", \"content\": text + \".\\n Using the above medical notes, please give your diagnosis and also determine if the patient has pulmonary embolism. Summarize the report (start with Summary:), give your short diagnosis (start with Diagnosis:), and answer the pulmonary embolism question only with a yes or no. If pulmonary embolism cannot be established, please say no and nothing more.\"},\n",
    "                ]\n",
    "            )\n",
    "            gentime = time.time() - start\n",
    "            ans = completion.choices[0].message.content\n",
    "            pattern = re.compile(r'Summary:(.*?)(?:Pulmonary embolism:)(.*)', re.DOTALL | re.IGNORECASE)\n",
    "            summary_match = pattern.search(ans)\n",
    "            summary = summary_match.group(1).strip() if summary_match else summary\n",
    "            summaries.append(summary)\n",
    "\n",
    "            # pe_match = re.search(r'Pulmonary Embolism: (.*)', ans, re.IGNORECASE)\n",
    "            pe_text = summary_match.group(2).strip() if summary_match else \"\"\n",
    "            res.append(pe_text)\n",
    "            answers.append(ans)\n",
    "            # print(ans, '\\n', gentime)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            token_len_exceeded_error = True\n",
    "            break\n",
    "\n",
    "    if token_len_exceeded_error:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        assert len(res) == len(df) == len(summaries) == len(answers), 'Lengths mismatch'\n",
    "    except AssertionError:\n",
    "        continue\n",
    "    \n",
    "    df['Summary'] = summaries\n",
    "    df['PE_Result_GPT35_16k'] = res\n",
    "    df['Answers'] = answers\n",
    "    \n",
    "    df.to_csv('patients_datewise_gpt35/' + out_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['Summary', 'PE_Result_GPT35_16k', 'Answers'], inplace=True)\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"In the realm of code, where logic pervades,\\nI'll weave a tale of a looping crusade.\\nA concept profound, yet elegantly clear,\\nRecursion, dear friends, is what we shall hear.\\n\\nImagine a function, a humble charmer,\\nWhose power lies not in its initial armor.\\nA call, it makes, to itself with grace,\\nLike mirrors reflecting, within time and space.\\n\\nA seed of thought, a problem to unravel,\\nEach iteration, a layer to travel.\\nWith each recursion, it breaks it down,\\nInto smaller fragments, truth shall be found.\\n\\nA fractal of code, a path untold,\\nExpanding dimensions, behold, behold!\\nIt dances with grace, in a mystical trance,\\nUnraveling the puzzle, giving it a chance.\\n\\nLike an echo resounding, back and forth,\\nIt explores the labyrinth, south, east, and north.\\nWith keen observation, it scrutinizes,\\nUnraveling mysteries, solving the prizes.\\n\\nBut beware, my friends, for recursion can be sly,\\nCaught in a loop, it may make you cry.\\nAn end condition, a beacon of light,\\nBreaks the spell, sets things right.\\n\\nThrough stacks and frames, it journeys afar,\\nWith elegance and grace, like a shining star.\\nSolving complex problems, layer by layer,\\nRecursion dances, with a purpose to bear.\\n\\nSo next time you ponder a puzzle, my friend,\\nRemember this concept, let your mind ascend.\\nWith recursion as your ally, code will unfold,\\nUnlocking the secrets, the stories untold.\", role='assistant', function_call=None, tool_calls=None) \n",
      " 10.907400369644165\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "# completion = client.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are an assistant for a medical practitioner, skilled in analyzing and summarizing medical notes and reports.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"f{} Using the above medical notes, please give your diagnosis and also determine if the patient has pulmonary embolism. Keep your diagnosis short, and answer the pulmonary embolism question with a yes or no.\"},\n",
    "#   ]\n",
    "# )\n",
    "# gentime = time.time() - start\n",
    "# print(completion.choices[0].message, '\\n', gentime)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
